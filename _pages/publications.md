---
layout: archive
title: "publications"
permalink: /publications/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

## Preprints and Media

*AI Automatons: AI Systems Intended to Imitate Humans.* 
Alexandra Olteanu, Solon Barocas, **Su Lin Blodgett**, Lisa Egede, Alicia DeVrio, and Myra Cheng. 
[[paper](https://arxiv.org/abs/2503.02250)]

*LLMs produce racist output when prompted in African American English.* 
**Su Lin Blodgett** and Zeerak Talat. 
Nature News and Views. 
[[article](https://www.nature.com/articles/d41586-024-02527-x)]

*Fairness and Sequential Decision Making: Limits, Lessons, and Opportunities.* 
Samer B. Nashed, Justin Svegliato, and **Su Lin Blodgett**. 
[[paper](https://arxiv.org/abs/2301.05753)]

*Risks of AI Foundation Models in Education.* 
**Su Lin Blodgett** and Michael Madaio. 
[[paper](https://arxiv.org/abs/2110.10024)]

*How to Write a Bias Statement: Recommendations for Submissions to the Workshop on Gender Bias in NLP.* 
Christian Hardmeier, Marta R. Costa-jussà, Kellie Webster, Will Radford, and **Su Lin Blodgett**. 
[[paper](https://arxiv.org/abs/2104.03026)]

## 2025

*Ethics and Bias in NLP.*
Zeerak Talat, **Su Lin Blodgett**.
**International Encyclopedia of Language and Linguistics, 3rd Edition**. Eds. Hilary Nesi and Petar Milin. Elsevier.

*The predatory fantasy of worker empowerment in AI marketing.*
Justine Zhang, **Su Lin Blodgett**, and Nina Markl.
AI x Crisis: Tracing New Directions Beyond Deployment and Use Workshop, Aarhus. [[paper](https://tisjune.github.io/papers/aarhus_2025_skills.pdf)]

*Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor.*
Alexandra Olteanu, **Su Lin Blodgett**, Agathe Balayn, Angelina Wang, Fernando Diaz, Flavio du Pin Calmon, Margaret Mitchell, Michael Ekstrand, Reuben Binns, and Solon Barocas.
NeurIPS Position Paper. [[paper](https://arxiv.org/abs/2506.14652)]

*Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems.* 
Myra Cheng, **Su Lin Blodgett**, Alicia DeVrio, Lisa Egede, and Alexandra Olteanu. 
ACL. **Senior Area Chair Highlights Award**. [[paper](https://aclanthology.org/2025.acl-long.1259/)]
  
*Understanding and Meeting Practitioner Needs When Measuring Representational Harms Caused by LLM-Based Systems.* 
Emma Harvey, Emily Sheng, **Su Lin Blodgett**, Alexandra Chouldechova, Jean Garcia-Gathright, Alexandra Olteanu, and Hanna Wallach. 
Findings of ACL. [[paper](https://aclanthology.org/2025.findings-acl.947/)]

*Position: Evaluating Generative AI Systems is a Social Science Measurement Challenge.* 
Hanna Wallach, Meera Desai, A. Feder Cooper, Angelina Wang, Chad Atalla, Solon Barocas, **Su Lin Blodgett**, Alexandra Chouldechova, Emily Corvi, P. Alex Dow, Jean Garcia-Gathright, Alexandra Olteanu, Nicholas Pangakis, Stefanie Reed, Emily Sheng, Dan Vann, Jennifer Wortman Vaughan, Matthew Vogel, Hannah Washington, and Abigail Z. Jacobs. 
ICML Position Paper. [[paper](https://arxiv.org/abs/2502.00561)]

*Measuring Machine Learning Harms from Stereotypes: Requires Understanding Who is Being Harmed by Which Errors in What Ways.* 
Angelina Wang, Xuechunzi Bai, Solon Barocas, and **Su Lin Blodgett**. 
FAccT. [[paper](https://dl.acm.org/doi/10.1145/3715275.3732046)]

*Evaluating the Social Impact of Generative AI Systems in Systems and Society.* 
Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, **Su Lin Blodgett**, Canyu Chen, Hal Daumé III, Jesse Dodge, Isabella Duan, Felix Friedrich, Avijit Ghosh, Usman Gohar, Sara Hooker, Yacine Jernite, Ria Kalluri, Alberto Lusoli, Alina Leidinger, Michelle Lin, Xiuzhu Lin, Sasha Luccioni, Jennifer Mickel, Margaret Mitchell, Jessica Newman, Anaelia Ovalle, Marie-Therese Png, Shubham Singh, Andrew Strait, Lukas Struppek, Arjun Subramonian. 
**The Oxford University Press Handbook of Generative AI**. Eds. Philip Hacker, Andreas Engel, Sarah Hammer, and Brent Mittelstadt. Oxford University Press. [[preprint](https://zeerak.org/papers/Evaluating_the_Social_Impact_of_Generative_AI_Systems_in_Systems_and_Society__preprint_.pdf)]

*"I Am the One and Only, Your Cyber BFF": Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI.* 
Myra Cheng, Alicia DeVrio, Lisa Egede, **Su Lin Blodgett**, and Alexandra Olteanu. 
ICLR Blogpost. [[blog post](https://iclr-blogposts.github.io/2025/blog/anthropomorphic-ai/)] [[paper](https://arxiv.org/abs/2410.08526)] 

*A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies.* 
Alicia DeVrio, Myra Cheng, Lisa Egede, Alexandra Olteanu\*, and **Su Lin Blodgett**\* (co-last authors). 
CHI. [[paper](https://dl.acm.org/doi/10.1145/3706598.3714038)]

*"It was 80% me, 20% AI": Seeking Authenticity in Co-Writing with Large Language Models.* 
Angel Hsing-Chi Hwang, Q. Vera Liao, **Su Lin Blodgett**, Alexandra Olteanu, and Adam Trischler. 
CSCW. [[paper](https://arxiv.org/abs/2411.13032)]

## 2024

*Evaluating Generative AI Systems is a Social Science Measurement Challenge.* 
Hanna Wallach, Meera Desai, Nicholas Pangakis, A. Feder Cooper, Angelina Wang, Solon Barocas, Alexandra Chouldechova, Chad Atalla, **Su Lin Blodgett**, Emily Corvi, P. Alex Dow, Jean Garcia-Gathright, Alexandra Olteanu, Stefanie Reed, Emily Sheng, Dan Vann, Jennifer Wortman Vaughan, Matthew Vogel, Hannah Washington, and Abigail Z. Jacobs. 
Workshop on Evaluating Evaluations (NeurIPS). [[paper](https://evaleval.github.io/accepted_papers/EvalEval_24_Wallach.pdf)]

*Gaps Between Research and Practice When Measuring Representational Harms Caused by LLM-Based Systems.* 
Emma Harvey, Emily Sheng, **Su Lin Blodgett**, Alexandra Chouldechova, Jean Garcia-Gathright, Alexandra Olteanu, and Hanna Wallach. 
Workshop on Evaluating Evaluations (NeurIPS). [[paper](https://evaleval.github.io/accepted_papers/EvalEval_24_Harvey.pdf)]

*Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP.* 
Pieter Delobelle, Giuseppe Attanasio, Debora Nozza, **Su Lin Blodgett**, and Zeerak Talat. 
EMNLP. [[paper](https://aclanthology.org/2024.emnlp-main.1207/)]

*ECBD: Evidence-Centered Benchmark Design for NLP.* 
Yu Lu Liu, **Su Lin Blodgett**, Jackie Chi Kit Cheung, Q. Vera Liao, Alexandra Olteanu, and Ziang Xiao. 
ACL. [[paper](https://aclanthology.org/2024.acl-long.861/)]

*Understanding the Impacts of Language Technologies’ Performance Disparities on African American Language Speakers.* 
Jay L. Cunningham, **Su Lin Blodgett**, Hal Daumé III, Christina Harrington, Hanna Wallach, and Michael Madaio. 
Findings of ACL. [[paper](https://aclanthology.org/2024.findings-acl.761/)]

*"*One-size-fits-all?*" Examining Expectations around What Constitute "Fair" or "Good" NLG System Behaviors.* 
Li Lucy, **Su Lin Blodgett**, Milad Shokouhi, Hanna Wallach, and Alexandra Olteanu. 
NAACL. [[paper](https://aclanthology.org/2024.naacl-long.61/)]

*The Perspectivist Paradigm Shift: Assumptions and Challenges of Capturing Human Labels.* 
Eve Fleisig, **Su Lin Blodgett**, Dan Klein, and Zeerak Talat. 
NAACL. [[paper](https://aclanthology.org/2024.naacl-long.126/)]

## 2023

*Responsible AI Considerations in Text Summarization Research: A Review of Current Practices.* 
Yu Lu Liu, Meng Cao, **Su Lin Blodgett**, Jackie Chi Kit Cheung, Alexandra Olteanu, and Adam Trischler. 
Findings of EMNLP. [[paper](https://aclanthology.org/2023.findings-emnlp.413/)]

*FairPrism: Evaluating Fairness-Related Harms in Text Generation.* 
Eve Fleisig, Aubrie N. Amstutz, Chad Atalla, **Su Lin Blodgett**, Hal Daumé III, Alexandra Olteanu, Emily Sheng, Dan Vann, and Hanna Wallach. 
ACL. [[paper](https://aclanthology.org/2023.acl-long.343/)]

*It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and Measurements of Performance.* 
Arjun Subramonian, Xingdi Yuan, Hal Daumé III, and **Su Lin Blodgett**. 
Findings of ACL. [[paper](https://aclanthology.org/2023.findings-acl.202/)]

*This Prompt is Measuring \<MASK\>: Evaluating Bias Evaluation in Language Models.* 
Seraphina Goldfarb-Tarrant, Eddie L. Ungless, Esma Balkır, and **Su Lin Blodgett**. 
Findings of ACL. [[paper](https://aclanthology.org/2023.findings-acl.139/)]

*Taxonomizing and Measuring Representational Harms: A Look at Image Tagging.* 
Jared Katzman, Angelina Wang, Morgan Scheuerman, **Su Lin Blodgett**, Kristen Laird, Hanna Wallach, and Solon Barocas. 
AAAI. [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/26670)]

## 2022

*Examining Responsibility and Deliberation in AI Impact Statements and Ethics Reviews.* 
David Liu, Priyanka Nanayakkara, Sarah Sakha, Grace Abuhamad, **Su Lin Blodgett**, Nicholas Diakopoulos, Jessica Hullman and Tina Eliassi-Rad. 
AIES. [[paper](https://dl.acm.org/doi/10.1145/3514094.3534155)]

*Deconstructing NLG Evaluation: Evaluation Practices, Assumptions, and Their Implications.* 
Kaitlyn Zhou, **Su Lin Blodgett**, Adam Trischler, Hal Daumé III, Kaheer Suleman, and Alexandra Olteanu. 
NAACL. [[paper](https://aclanthology.org/2022.naacl-main.24/)]

*Beyond "Fairness": Structural Injustice Lenses On AI for Education.* 
Michael Madaio, **Su Lin Blodgett**, Elijah Mayfield, and Ezekiel Dixon-Román. 
**The Ethics of Artificial Intelligence in Education: Current Challenges, Practices and Debates**. Eds. Wayne Holmes and Kaśka Porayska-Pomsta. Routledge.

*Examining Political Rhetoric with Epistemic Stance Detection.* 
Ankita Gupta, **Su Lin Blodgett**, Justin Gross, and Brendan O'Connor. 
Workshop on Natural Language Processing and Computational Social Science (NLP+CSS). [[paper](https://aclanthology.org/2022.nlpcss-1.11/)]

## 2021

*Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets.* 
**Su Lin Blodgett**, Gilsinia Lopez, Alexandra Olteanu, Robert Sim, and Hanna Wallach. 
ACL. [[paper](https://aclanthology.org/2021.acl-long.81/)] [[slides](https://sblodgett.github.io/files/acl-2021-salmon-slides.pdf)]

*A Survey of Race, Racism, and Anti-Racism in NLP.* 
Anjalie Field, **Su Lin Blodgett**, Zeerak Talat, and Yulia Tsvetkov. 
ACL. [[paper](https://aclanthology.org/2021.acl-long.149/)]
<!-- *Representational Harms in Image Captioning and Labeling.* Jared Katzman, Solon Barocas, **Su Lin Blodgett**, Kristen Laird, Hanna Wallach and Morgan Klaus Scheuerman. Beyond Fairness: Towards a Just, Equitable, and Accountable Computer Vision Workshop (CVPR). [[pdf](https://drive.google.com/file/d/1oJp8CqNpYEsOlO8cwv4cTnHGbOjWxEZ-/view)] -->
  <!-- * also presented at the Measures and Best Practices for Responsible AI Workshop at KDD -->

## 2020

*PhD Thesis: Sociolinguistically Driven Approaches for Just Natural Language Processing.* 
**Su Lin Blodgett**. [[thesis](https://scholarworks.umass.edu/dissertations_2/2092/)]

*Language (Technology) is Power: A Critical Survey of "Bias" in NLP.* 
**Su Lin Blodgett**, Solon Barocas, Hal Daumé III, and Hanna Wallach. 
ACL. [[paper](https://aclanthology.org/2020.acl-main.485/)] [[slides](https://sblodgett.github.io/files/acl-2020-power-slides.pdf)]

## 2018

*Twitter Universal Dependency Parsing for African-American and Mainstream American English.* 
**Su Lin Blodgett**, Johnny Tian-Zheng Wei, and Brendan O'Connor. 
ACL. [[paper](https://aclanthology.org/P18-1131/)] [[data](http://slanglab.cs.umass.edu/TwitterAAE/)]

*Monte Carlo Syntax Marginals for Exploring and Using Dependency Parses.* 
Katherine Keith, **Su Lin Blodgett**, and Brendan O'Connor. 
NAACL. [[paper](https://aclanthology.org/N18-1084/)]

## 2017

*A Dataset and Classifier for Recognizing Social Media English.* 
**Su Lin Blodgett**, Johnny Tian-Zheng Wei, and Brendan O'Connor. 
Workshop on Noisy User-Generated Text (W-NUT). **W-NUT Best Paper Award.** [[paper](https://aclanthology.org/W17-4408/)] [[data](http://slanglab.cs.umass.edu/TwitterLangID/)]

*Racial Disparity in Natural Language Processing: A Case Study of Social Media African-American English.* 
**Su Lin Blodgett** and Brendan O'Connor. 
Fairness, Accountability, and Transparency in Machine Learning Workshop (FAT/ML). [[paper](https://arxiv.org/pdf/1707.00061.pdf)] [[data](http://slanglab.cs.umass.edu/TwitterLangID/)]

## 2016

*Demographic Dialectal Variation in Social Media: A Case Study of African-American English.* 
**Su Lin Blodgett**, Lisa Green, and Brendan O'Connor. 
EMNLP. [[paper](https://aclanthology.org/D16-1120/)] [[data](http://slanglab.cs.umass.edu/TwitterAAE/)]

*Visualizing Textual Models with In-Text and Word-as-Pixel Highlighting.* 
Abram Handler, **Su Lin Blodgett**, and Brendan O'Connor. 
Workshop on Human Interpretability in Machine Learning (WHI). [[paper](https://arxiv.org/pdf/1606.06352v1.pdf)]

<!-- {% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %}
 -->
